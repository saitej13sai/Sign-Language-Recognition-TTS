# Sign-Language-Recognition-TTS
This project detects hand gestures using a webcam and translates them into text and speech using a deep learning model. The system recognizes predefined gestures and speaks out the detected sign using pyttsx3 for text-to-speech (TTS).


Technologies Used
Python – Core programming language;
OpenCV – For real-time webcam input and visualization;
MediaPipe – To detect and track hand landmarks;
TensorFlow/Keras – For the deep learning model;
NumPy – To handle array operations;
pyttsx3 – For text-to-speech conversion.

